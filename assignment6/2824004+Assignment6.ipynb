{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Systems 2023: Practical Assignment 06 \n",
    "## Logical Agents\n",
    "\n",
    "Your name: Chantal Elena Ariu\n",
    "\n",
    "Your VUnetID: car103\n",
    "\n",
    "If you do not provide your name and VUnetID we will not accept your submission. \n",
    "\n",
    "### Learning objectives\n",
    "At the end of this exercise you should be able to work with logical agents on the Schnapsen platform\n",
    "\n",
    "1. Be able to apply a SAT solver to check for satisfiability and entailment (bots)\n",
    "\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "In this worksheet we'll get to know Propositional Logic and RDF.\n",
    "We start building a knowledge graph based agent for playing Schnapsen. The idea is to represent the game and the game states fully in RDF and use queries and logical entailments for getting information.\n",
    "We are not implementing any game play strategy yet.\n",
    "\n",
    "First things first, let's deal with dependencies for using the kb bot, namely numpy and scipy. They should be installed fairly easily via \"pip install numpy\", \"pip install scipy\".\n",
    "Furthermore you need the packages rdflib and owlrl to work with knowledge graphs. These packages can also be installed by using \"pip install rdflib\" and \"pip install owlrl\".\n",
    "rdflib is a in memory database for RDF.\n",
    "owlrl is a reasoning library for RDF-S and OWL which uses rdflib.\n",
    "\n",
    "\n",
    "### Practicalities\n",
    "\n",
    "Follow this Notebook step-by-step. \n",
    "\n",
    "Of course, you can do the exercises in any Programming Editor of your liking. But you do not have to. Feel free to simply write code in the Notebook. Please use your studentID+Assignment6.ipynb as the name of the Notebook.  \n",
    "\n",
    "Note: unlike the courses dedicated to programming we will not evaluate the style of the programs. But we will, however, test your programs on other data that we provide, and your program should give the correct output to the test-data as well.\n",
    "\n",
    "As was mentioned, the assignment is graded as pass/fail. To pass you need to have either a full working code or an explanation of what you tried and what didn't work for the tasks that you were unable to complete (you can use multi-line comments or a text cell).\n",
    "\n",
    "## Initialising \n",
    "\n",
    "First, let us make sure the necessary packages are installed, and imported. Run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: schnapsen 0.0.3\n",
      "Uninstalling schnapsen-0.0.3:\n",
      "  Successfully uninstalled schnapsen-0.0.3\n",
      "Cloning into 'schnapsen'...\n",
      "remote: Enumerating objects: 1731, done.\u001b[K\n",
      "remote: Counting objects: 100% (826/826), done.\u001b[K\n",
      "remote: Compressing objects: 100% (271/271), done.\u001b[K\n",
      "remote: Total 1731 (delta 608), reused 622 (delta 527), pack-reused 905\u001b[K\n",
      "Receiving objects: 100% (1731/1731), 2.18 MiB | 24.55 MiB/s, done.\n",
      "Resolving deltas: 100% (964/964), done.\n",
      "Obtaining file:///Users/chantalariu/Documents/Uni/Year%201/P2/Intelligent%20Systems/Assignments/assignment6/schnapsen\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: class-resolver>=0.0.10 in /opt/homebrew/lib/python3.11/site-packages (from schnapsen==0.0.3) (0.4.2)\n",
      "Requirement already satisfied: click==8.1.3 in /opt/homebrew/lib/python3.11/site-packages (from schnapsen==0.0.3) (8.1.3)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in /opt/homebrew/lib/python3.11/site-packages (from schnapsen==0.0.3) (1.3.2)\n",
      "Requirement already satisfied: joblib==1.3.2 in /opt/homebrew/lib/python3.11/site-packages (from schnapsen==0.0.3) (1.3.2)\n",
      "Requirement already satisfied: flask==2.3.3 in /opt/homebrew/lib/python3.11/site-packages (from schnapsen==0.0.3) (2.3.3)\n",
      "Requirement already satisfied: Werkzeug==3.0.1 in /opt/homebrew/lib/python3.11/site-packages (from schnapsen==0.0.3) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /opt/homebrew/lib/python3.11/site-packages (from flask==2.3.3->schnapsen==0.0.3) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /opt/homebrew/lib/python3.11/site-packages (from flask==2.3.3->schnapsen==0.0.3) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /opt/homebrew/lib/python3.11/site-packages (from flask==2.3.3->schnapsen==0.0.3) (1.7.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn==1.3.2->schnapsen==0.0.3) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn==1.3.2->schnapsen==0.0.3) (1.11.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn==1.3.2->schnapsen==0.0.3) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/lib/python3.11/site-packages (from Werkzeug==3.0.1->schnapsen==0.0.3) (2.1.3)\n",
      "Building wheels for collected packages: schnapsen\n",
      "  Building editable for schnapsen (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for schnapsen: filename=schnapsen-0.0.3-0.editable-py3-none-any.whl size=16266 sha256=37fec2ade3012c013cbd265a4cdbeba062006bcb8f265bf08d23ef236713ca44\n",
      "  Stored in directory: /private/var/folders/p9/3vhw02td3qzcsm583w1m4mgw0000gn/T/pip-ephem-wheel-cache-wnt4hhvs/wheels/16/07/76/69cf8167dec4bf195293d4e1ad9a733b7c5575438808cfe43e\n",
      "Successfully built schnapsen\n",
      "Installing collected packages: schnapsen\n",
      "Successfully installed schnapsen-0.0.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# If you are on a UNIX system (Linux or Mac OS)\n",
    "!python3 -m pip uninstall schnapsen -y && rm -rf schnapsen && git clone https://github.com/intelligent-systems-course/schnapsen && cd schnapsen && python3 -m pip install -e . && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are on Windows\n",
    "!pip uninstall schnapsen -y && rd /s /q schnapsen && git clone https://github.com/intelligent-systems-course/schnapsen && cd schnapsen && pip install -e . && cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you install a python package, e.g., `schnapsen`, directly from a Jupyter Notebook, with a command, e.g., `!rm -rf schnapsen && git clone https://github.com/intelligent-systems-course/schnapsen && cd schnapsen && pip install -e . && cd ..`, your Python kernel might not know that the package is installed yet. This can throw a `ModuleNotFoundError`, `ModuleNotFoundError: No module named 'schnapsen.game'`.\n",
    "\n",
    "If you encounter this, simply restart the kernel and proceed. I don't know what kind of IDE you use, but VS Code is pretty handy and handle this pretty nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from schnapsen.game import Bot, Move, PlayerPerspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAT solving and Entailment checking \n",
    "\n",
    "We will start with some exercises to use an existing SAT solver to check for satisfiability and entailment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kb\n",
    "\n",
    "# Define our symbols\n",
    "A = kb.Boolean('A')\n",
    "B = kb.Boolean('B')\n",
    "C = kb.Boolean('C')\n",
    "D = kb.Boolean(\"D\")\n",
    "\n",
    "# P = kb.Boolean('P')\n",
    "# Q = kb.Boolean('Q')\n",
    "# R = kb.Boolean('R')\n",
    "\n",
    "# Create a new knowledge base\n",
    "kb = kb.KB()\n",
    "\n",
    "# Add clauses\n",
    "# kb.add_clause(A, B, C)\n",
    "# kb.add_clause(~A, B)\n",
    "# kb.add_clause(~B, C)\n",
    "# kb.add_clause(B, ~C)\n",
    "\n",
    "# kb.add_clause(P, Q)\n",
    "# kb.add_clause(~Q, R)\n",
    "# kb.add_clause(~R, ~P)\n",
    "# kb.add_clause(~Q, P)\n",
    "# kb.add_clause(~P, Q)\n",
    "\n",
    "# kb.add_clause(A, B)\n",
    "# kb.add_clause(~B, A)\n",
    "# kb.add_clause(~A, C)\n",
    "# kb.add_clause(~A, D)\n",
    "\n",
    "\n",
    "# for refutation\n",
    "kb.add_clause(~A, ~B)\n",
    "kb.add_clause(B, ~A)\n",
    "kb.add_clause(A, ~C)\n",
    "kb.add_clause(A, ~D)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file first defines the three boolean symbols we will use (A, B and C), creates an empty knowledge base, and then adds the four following clauses:\n",
    "> A or B or C <br>\n",
    "> (not A) or B <br>\n",
    "> (not B) or C<br>\n",
    "> B or not C\n",
    "\n",
    "### Task 1\n",
    "Are there any models (assignments of values to these variables that make all clauses true)? Write down all the models of the knolwedge base in the following cell. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. A = True, B = True, C = True\n",
    "2. A = True, B = True, C = False\n",
    "3. A = False B = True, C = True\n",
    "4. A = False, B = True, C = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the script and report the output in the cell after the code. Explain what it means.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{A: False, D: False, C: False, B: False}\n",
      "{A: False, D: False, C: False, B: True}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Print all models of the knowledge base\n",
    "for model in kb.models():\n",
    "    print(model)\n",
    "\n",
    "# Print out whether the KB is satisfiable (if there are no models, it is not satisfiable)\n",
    "print(kb.satisfiable())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put your answers here\n",
    "Report1=\"\"\"\n",
    "The output: \"{A: False, B: True, C: True}\n",
    "{A: True, B: True, C: True}\n",
    "True\" means that the algorithm found two models of the knowledge base and since it was able to find models in the first place\n",
    "it prints true since a knowledge base is satisfiable if there is at least one model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to adapt your first knowledge-base, by adding stuffâ€¦. \n",
    "\n",
    "## Tasks 2: \n",
    "Add a clause to the knowledge base to that it becomes unsatisfiable. Report the line of code you added, and in a separate line, the result that you get from the SAT solver and your script. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "not B\n",
    "\n",
    "Output from sat solving after adding not B to knowledge base: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can already to build your own knowledge base, and do reasoning/inferencing with it. For example, check satisfiability of one of the questions of the working group automatically. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:\n",
    "Let  KB be the  knowledge base introduced in Exercise 7 of the Worksheet on Logical Agents: KB=\n",
    "> (P v Q) ^ (Q -> R) ^ (R -> -P)<br>\n",
    "> -(P <-> - Q)\n",
    "\n",
    "Write a new version of the script above to prove or disprove whether KB is satisfiable or not. You can put both the knowledge base construction (you will have to translate the axioms into CNF by hand before adding them to the KB), the printing of the model and the satisfiability check in the next cell. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PVQ, -QVR, -RV-P, -QVP, Qv-Q, -PVP, -PV-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: \n",
    "We will now work with the following knowledge base KB:\n",
    "\n",
    ">-A -> B <br> \n",
    "> B -> A <br>\n",
    "> A -> (C ^ D)\n",
    "\n",
    "Convert it to clause normal form, and write a script that creates this knowledge base as you did before. There are different subtasks: \n",
    "1) Print out its models and report them. <br>\n",
    "2) The knowledge base entails A ^ C ^ D. Explain in your own words what this says about the possible models for the knowledge base?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AVB,-BVA,-AVC,-AVD, A,C,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{A: True, D: True, C: True, B: False}\n",
    "{A: True, D: True, C: True, B: True}\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Report2 = \"\"\"\n",
    "It means that A, C, and D need to always be true in the models, meaning that there are two possible models\n",
    "since B can be either true or false but the rest have to be true.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous question, you have shown that A ^ C ^ D is entailed by KB semantically (following the definition of entailment), where you used the prover to give you all the models. Now let us see whether you can actually prove entailment using the SAT solver directly.\n",
    "\n",
    "### Task 5: \n",
    "Show entailment of A ^ C ^ D by a proof by refutation. Write the script like above with the knowledge base your create in the following executable cell, including the control statements. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{A: False, D: False, C: False, B: False}\n",
    "{A: False, D: False, C: False, B: True}\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain in your own words what you have done, and what you can conclude from the output of your script for Task 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Report3=\"\"\"\n",
    "I have taken the knowledge base and negated all of it and the output now shows that A, C, D are all false for any model\n",
    "which is how we can show the entailment of A or C or D by refutation (by negating everything and sat solving after that).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Task: Collect all the results\n",
    "\n",
    "Uncomment and run this cell (and all the cells above) to generate the text file that you have to hand in together with the notebook on canvas!\n",
    "\n",
    "### Please hand in only the text file which is generated by this method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportToText(*args):\n",
    "    with open(args[0], \"w\") as f:\n",
    "        for argument in args:\n",
    "            f.write(\"{}\\n\".format(argument))\n",
    "\n",
    "\n",
    "exportToText(\"assignment6.txt\", Report1, Report2, Report3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
