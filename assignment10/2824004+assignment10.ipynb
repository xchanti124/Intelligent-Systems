{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Systems 2023: Practical Assignment 10\n",
    "\n",
    "## Machine Learning Introduction\n",
    "\n",
    "Your name: Chantal Ariu\n",
    "\n",
    "Your VUnetID: car103\n",
    "\n",
    "If you do not provide your name and VUnetID we will not accept your submission. \n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "At the end of this exercise you should be able to work with some basic Machine Learning concepts, and implement and evaluate simple classifiers for *spam classification* using the popular machine learning library scikit-learn(https://scikit-learn.org/stable/).\n",
    "Scikit-learn offers a many helpful methods for creating simple machine learning models and to perform data science.\n",
    "\n",
    "In this assignment you will:\n",
    "1. Use pandas to read a dataset from a comma-separated-value (.csv) file.\n",
    "2. You should be able to create tf-idf feature vectors with scikit-learn.\n",
    "3. You should be able to create a simple classification and evaluate basic classification models.\n",
    "4. You should have learned to improve classification models for textual data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Practicalities\n",
    "\n",
    "Follow this Notebook step-by-step. For this course it is necessary that you manipulate the python programmes we provide. You can do the exercises in any Programming Editor of your liking. Still, please fill in the questions in this notebook as usual. \n",
    "\n",
    "Please use your studentID+Assignment10.ipynb as the name of the Notebook, and fill in the missing cells.   \n",
    "\n",
    "Note: unlike the courses dedicated to programming we will not evaluate the style of the programs. But we will, however, test your programs on other data that we provide, and your program should give the correct output to the test-data as well.\n",
    "\n",
    "As was mentioned, the assignment is graded as pass/fail. To pass you need to have either a full working code or an explanation of what you tried and what didn't work for the tasks that you were unable to complete (you can use multi-line comments or a text cell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install some packages\n",
    "\n",
    "First we need to install some additional packages that we will use throughout this assignment.\n",
    "This might take a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.1.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting numpy<2,>=1.26.0 (from pandas)\n",
      "  Downloading numpy-1.26.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pandas-2.1.4-cp312-cp312-macosx_11_0_arm64.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.2-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "Successfully installed numpy-1.26.2 pandas-2.1.4 python-dateutil-2.8.2 pytz-2023.3.post1 six-1.16.0 tzdata-2023.3\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/chantalariu/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from scikit-learn) (1.26.2)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.11.4-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.9/217.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp312-cp312-macosx_12_0_arm64.whl (9.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.11.4-cp312-cp312-macosx_12_0_arm64.whl (29.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.6/29.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 scipy-1.11.4 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install pandas\n",
    "!python3 -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classification models with Sci-Kit Learn.\n",
    "\n",
    "With this notebbook, you have downloaded a small .csv file containing a public spam/ham SMS dataset that is often used for text classification purposes.\n",
    "We will load this dataset with the pandas library (https://pandas.pydata.org/), which is often used for data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv ('spam.csv', encoding = \"ISO-8859-1\")\n",
    "df.dropna(how=\"any\", inplace=True, axis=1)\n",
    "df.columns = ['label', 'message']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the resulting pandas dataframe contains an index column, a label, and the message.\n",
    "Let's first have a look at the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "For this first task, we ask you to do a basic data science task. Try to get an idea about the dataset by checking how balanced/unbalanced the dataset is. To do this, you need to compute the proportion of the *ham* and the *spam* class.\n",
    "\n",
    "Find a Pandas function to compute the frequency of the labels to get an idea of the label distribution. \n",
    "Then write a short description of your results.\n",
    "What percentage of the messages are labelled as spam?\n",
    "\n",
    "*Hint: Have a look at the Pandas documentation (https://pandas.pydata.org/docs/). There a many ways to get your answer!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_proportions = df['label'].value_counts(normalize=True)\n",
    "print(class_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport1 = \"\"\"\n",
    "The output states that ham has a percentage of 86.59 percent whereas spam has a percentage of 13.41 percent.\n",
    "This means that in our dataset there is quite an unbalance going on between ham and spam class.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snipped will create textual features, as discussed in last weeks lecture. We will create tf-idf vectors and will append them to our pandas dataframe.\n",
    "Then we will perform a simple train/test split of our dataset, using the scikit-learn splitting functions.\n",
    "\n",
    "Have a look at the different parts that we created. What do the dataframes X_train, y_train, X_test, y_test contain?\n",
    "Try to understand what is happening here by also having a look at the scikit-learn documentation (https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#compute the tf-idf vectors for the messages and create a new dataframe for them\n",
    "v = TfidfVectorizer()\n",
    "tf_idf = v.fit_transform(df['message'])\n",
    "df_tfidf = pd.DataFrame(tf_idf.toarray(), columns=v.get_feature_names_out())\n",
    "\n",
    "#combine the original dataframe with the dataframe for the tf-idf vectors\n",
    "dataframes = [df, df_tfidf]\n",
    "df_new = pd.concat(dataframes, axis=1)\n",
    "\n",
    "#split the dataset into training and test set\n",
    "train, test = train_test_split(df_new, test_size=0.9)\n",
    "\n",
    "#separate feature matrices X from label vector y\n",
    "X_train = train.iloc[:, 3:]\n",
    "X_test = test.iloc[:, 3:]\n",
    "y_train = train['label']\n",
    "y_test = test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>ó_</th>\n",
       "      <th>û_</th>\n",
       "      <th>û_thanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 8671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "5101  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "4650  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "1238  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2869  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "130   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "...   ...     ...           ...   ...   ...          ...          ...   \n",
       "832   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2306  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2246  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2995  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2434  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "\n",
       "      0125698789   02  0207  ...   ó_   û_  û_thanks  ûªm  ûªt  ûªve   ûï  \\\n",
       "5101         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "4650         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "1238         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "2869         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "130          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "...          ...  ...   ...  ...  ...  ...       ...  ...  ...   ...  ...   \n",
       "832          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "2306         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "2246         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "2995         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "2434         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "\n",
       "      ûïharry   ûò  ûówell  \n",
       "5101      0.0  0.0     0.0  \n",
       "4650      0.0  0.0     0.0  \n",
       "1238      0.0  0.0     0.0  \n",
       "2869      0.0  0.0     0.0  \n",
       "130       0.0  0.0     0.0  \n",
       "...       ...  ...     ...  \n",
       "832       0.0  0.0     0.0  \n",
       "2306      0.0  0.0     0.0  \n",
       "2246      0.0  0.0     0.0  \n",
       "2995      0.0  0.0     0.0  \n",
       "2434      0.0  0.0     0.0  \n",
       "\n",
       "[557 rows x 8671 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a look at the different dataframes here\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "\n",
    "In the lecture, we have introduced the naive Bayes classification algorithm and have already computed various examples by hand. Here, we will use scikit-learn to train your first own classification model for spam classification.\n",
    "However, all examples from the lecture were using categorical features, while our tf-idf vectors here are real-valued features. \n",
    "Thus, the model used here will be slightly different than what we have seen in the lecture.\n",
    "\n",
    "\n",
    "\n",
    "### Task 2\n",
    "\n",
    "Use the training and test set created in the previous cell and train a Naive Bayes classifier using sci-kit learn.\n",
    "Please have a look at the documentation on how to use classification model using X_train and y_train as an input.\n",
    "Afterwards compute the accuracy of your classfier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8693918245264207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have seen, the accuracy of your Naive Bayes classifier should be over 85%.\n",
    "This seems to be a very good score, for a very simple classification model and simple tf-idf features.\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Have a look at different evaluation metrics for your classifier and discuss the suitability of accuracy for the spam classification task.\n",
    "Have a look at the definition of accuracy and come up with another metric, which is better suited for our problem\n",
    "\n",
    "*Hint: Have a look at this documentation and try out different evaluation metrics: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8693918245264207\n",
      "Naive Bayes Jaccard Score: 0.02092675635276532\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      1.00      0.93      4346\n",
      "        spam       1.00      0.02      0.04       669\n",
      "\n",
      "    accuracy                           0.87      5015\n",
      "   macro avg       0.93      0.51      0.49      5015\n",
      "weighted avg       0.89      0.87      0.81      5015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score, classification_report\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label='spam')\n",
    "recall = recall_score(y_test, y_pred, pos_label='spam')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
    "jaccard = jaccard_score(y_test, y_pred, pos_label='spam')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "print(\"Naive Bayes Jaccard Score:\",jaccard)\n",
    "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport2 = \"\"\"\n",
    "As stated in the documentation, I first used the more common evaluation metrics: precision, recall and f1. \n",
    "- Precision output: 1.0 (measure of accuracy of positive predictions) --> 100%\n",
    "- Recall output: 0.21 (measure of proportion of actual positives that were identified correctly) --> ~21%\n",
    "- F1 output: 0.04 (measures harmonic mean between precision and recall) --> ~4%\n",
    "- Jaccard output: 0.02 (defined as size of intersection divided by the size of the union of two label sets) --> ~2%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Come up with any improvements for the classification model here.\n",
    "You can come up with a new method and/or different features to improve the classification.\n",
    "Can you beat the baseline Naive Bayes model?\n",
    "\n",
    "If you try out a different classification model, the training of the model might take a couple of seconds.\n",
    "\n",
    "Write at least 10 sentences describing your improvements and why these improvements are helping to improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9647058823529412\n",
      "SVM Jaccard Score: 0.7416058394160584\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      4346\n",
      "        spam       0.97      0.76      0.85       669\n",
      "\n",
      "    accuracy                           0.96      5015\n",
      "   macro avg       0.97      0.88      0.92      5015\n",
      "weighted avg       0.96      0.96      0.96      5015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Here, we will initialize the SVM classifier model and pass the standard parameters that we will need\n",
    "svm_classifier = SVC(kernel='sigmoid', gamma=1.0, class_weight='balanced')\n",
    "\n",
    "# Here, we use the function .fit() (form sklearn documentation) to train the model\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Now we compute the accuracy and print it out\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "\n",
    "precision_svm = precision_score(y_test, y_pred_svm, pos_label='spam')\n",
    "recall_svm = recall_score(y_test, y_pred_svm, pos_label='spam')\n",
    "f1_svm = f1_score(y_test, y_pred_svm, pos_label='spam')\n",
    "jaccard_svm = jaccard_score(y_test, y_pred_svm, pos_label='spam')\n",
    "\n",
    "# print(\"SVM Precision:\", precision_svm)\n",
    "# print(\"SVM Recall:\", recall_svm)\n",
    "# print(\"SVM F1 Score:\", f1_svm)\n",
    "print(\"SVM Jaccard Score:\", jaccard_svm)\n",
    "\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport3 = \"\"\"\n",
    "During our intro to ai course, I was doing research on the SVM model (Support Vector Machine Model) and therefore wanted\n",
    "to look into it a little bit more to test whether it would perform better than the Naive Bayes model. I then went on\n",
    "to research how to use an SVM model with sklearn and ended up on this website initially https://scikit-learn.org/stable/modules/svm.html. \n",
    "After reading about SVM on that website, I knew that theoretically, the SVM model would perform better than Naive Bayes\n",
    "model, especially since the SVM model can take the parameter 'class_weight' and if set to 'balanced' (which is what I did),\n",
    "it would be very beneficial since the dataset we are using is very unbalanced.\n",
    "\n",
    "After doing the initial research and gathering the theoretical knowledge, I followed the guides on sklearn's documentation\n",
    "as well as the information from the following website: https://www.milindsoorya.com/blog/build-a-spam-classifier-in-python\n",
    "to gather more insight on how to train and implement an SVM model. Once I understood how to do so, I initialized the \n",
    "SVM classifier model, trained it, and used the same metrics I used for analyzing the Naive Bayes model, for my SVM model.\n",
    "\n",
    "Now we can directly compare the performances using the output from the classification_report() function as well as the\n",
    "Jaccard Scores and the accuracy scores, we get the following results:\n",
    "\n",
    "Naive Bayes Accuracy: 0.8693918245264207\n",
    "Naive Bayes Jaccard Score: 0.02092675635276532\n",
    "Naive Bayes Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         ham       0.87      1.00      0.93      4346\n",
    "        spam       1.00      0.02      0.04       669\n",
    "\n",
    "    accuracy                           0.87      5015\n",
    "   macro avg       0.93      0.51      0.49      5015\n",
    "weighted avg       0.89      0.87      0.81      5015\n",
    "\n",
    "\n",
    "SVM Accuracy: 0.9647058823529412\n",
    "SVM Jaccard Score: 0.7416058394160584\n",
    "SVM Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         ham       0.96      1.00      0.98      4346\n",
    "        spam       0.97      0.76      0.85       669\n",
    "\n",
    "    accuracy                           0.96      5015\n",
    "   macro avg       0.97      0.88      0.92      5015\n",
    "weighted avg       0.96      0.96      0.96      5015\n",
    "\n",
    "As we can see, my SVM model improved the performance by a significant amount. In particular, if we start the analysis\n",
    "at the accuracy score, we can see that Naive Bayes Accuracy score is at 86.94% approximately, while the SVM Accuracy\n",
    "score is at 96.47% approximately. This is an improvement of more than 5%. Moving on to the Jaccard score (using spam as\n",
    "the label), we had a score of approximately 2% using the Naive Bayes model, which is very low compared to the Jaccard\n",
    "score of my SVM model, which is at approximately 74%, resulting in a huge difference.\n",
    "As for the other metrics, we can see that almost every metric is improved upon very significantly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Task: Collect all the results\n",
    "\n",
    "Uncomment and run this cell (and all the cells above) to generate the text file that you have to hand in together with the notebook on canvas!\n",
    "\n",
    "### Please hand in only the text file which is generated by this method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportToText(*args):\n",
    "    with open(args[0], \"w\") as f:\n",
    "        for argument in args:\n",
    "            f.write(\"{}\\n\".format(argument))\n",
    "\n",
    "exportToText(\"assignment10.txt\", MyReport1, MyReport2, MyReport3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
